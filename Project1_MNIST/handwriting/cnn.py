#__author:import numpy as npimport  osimport timeimport tensorflow as tffrom Project1_MNIST.handwriting.read import  *os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'#读取数据trX, trY, teX, teY = readdata()#超参数batch_size = 180test_size = 5000g_CNN = tf.Graph()with g_CNN.as_default():    # Y_all = tf.constant(loady[:], dtype=tf.float32)    def init_weights(shape):        return tf.Variable(tf.random_normal(shape,stddev=0.1))    def Model(X,w,w2,w21,w3,w4,w_o,p_keep_conv,p_keep_hidden):        lla  = tf.nn.relu(tf.nn.conv2d(X,w,strides=[1,1,1,1],padding="SAME"))        ll = tf.nn.max_pool(lla,ksize=[1,2,2,1],strides=[1,2,2,1],padding="SAME")        ll = tf.nn.dropout(ll,p_keep_conv)        l2a = tf.nn.relu(tf.nn.conv2d(ll, w2, strides=[1, 1, 1, 1], padding="SAME"))        l2 = tf.nn.max_pool(l2a, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding="SAME")        l2 = tf.nn.dropout(l2, p_keep_conv)        l21a = tf.nn.relu(tf.nn.conv2d(l2, w21, strides=[1, 1, 1, 1], padding="SAME"))       # l21 = tf.nn.max_pool(l21a, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding="SAME")#无法pool 后面有问题的        l21 = tf.nn.dropout(l21a, p_keep_conv)        l3a  = tf.nn.relu(tf.nn.conv2d(l21,w3,strides=[1,1,1,1],padding="SAME"))        l3 = tf.nn.max_pool(l3a,ksize=[1,2,2,1],strides=[1,2,2,1],padding="SAME")        l3 = tf.reshape(l3,[-1,w4.get_shape().as_list()[0]])        l3 = tf.nn.dropout(l3,p_keep_conv)        l4  =  tf.nn.relu(tf.matmul(l3,w4))        l4 = tf.nn.dropout(l4,p_keep_hidden)        pyx = tf.matmul(l4,w_o)        return pyx    def loss(Y_Model,Y_ture):        return tf.square(Y_Model-Y_ture)    def Verify(tey,pre_y,i,test_size = 2500):        num = 0        for j in range(test_size):            if tey[j] ==pre_y[j]:                num +=1        return float(num * 100 / test_size)    X = tf.placeholder('float',[None,28,28,1])    Y = tf.placeholder("float",[None,10])    w = init_weights([3,3,1,16])    w2 = init_weights([3,3,16,32])    w21 = init_weights([3, 3, 32, 64])    w3 = init_weights([3,3,64,64])    w4 = init_weights([64*4*4,64])    w_o = init_weights([64,10])    leaning_rate = tf.placeholder("float")    p_keep_conv = tf.placeholder("float")    p_keep_hidden = tf.placeholder("float")    py_x = Model(X,w,w2,w21,w3,w4,w_o,p_keep_conv,p_keep_hidden)#预测值    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=py_x,labels=Y))    # COST = loss(py_x,Y)    # cross_entropy = -tf.reduce_sum((py_x * tf.log(Y))    # train_step = tf.train.GradientDescentOptimizer(0.01).minimize(cross_entropy)    train_op = tf.train.GradientDescentOptimizer(leaning_rate).minimize(cost)    predict_op = tf.argmax(py_x,1)    global_step = tf.Variable(0, name="global_step",trainable=False)  # 保存模型的计数器    saver = tf.train.Saver() #保存之前的变量def CNN():    #保存地址    ckpt_dir = "G:\PYTHON_PRO\Project1_MNIST\handwriting\ckpt_dir_Cnn"    if not os.path.exists(ckpt_dir):        os.makedirs(ckpt_dir)    with tf.Session(graph = g_CNN) as sess:        tf.global_variables_initializer().run()        global_step.eval()        for i in range(300):    # 训练 先打包 再一次次训练（填数据，自动校正 W 参数）            time_begin = time.time()            training_batch = zip(range(0,len(teX),batch_size),                                       range(batch_size,len(teX)+1,batch_size))            for start ,end in training_batch:                sess.run(train_op,feed_dict={                    X:trX[start:end],Y:trY[start:end],                    leaning_rate :int(1000*(0.001+(1)/(10+np.exp((i-50)*0.04))))/1000.0,                    p_keep_hidden : 0.7,p_keep_conv : 0.9})    #验证            pre_y = onehot_mun(sess.run(predict_op, feed_dict={X: teX[:],p_keep_hidden:1,p_keep_conv :1}))            result = Verify(teY,pre_y,i,test_size)    #模型保存            global_step.assign(i).eval()  # 更新计数器            saver.save(sess, ckpt_dir + "/model.ckpt", global_step=global_step)  # 存储            print("第%d次:精度为%.2f%%,耗时%.2fs" % (i + 1, result,(-time_begin+time.time())))if __name__ == '__main__':    CNN()